{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "aMdwXfJGd36I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EGxlVeMd2_y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the real and forged signature datasets"
      ],
      "metadata": {
        "id": "kNywT1fUd7xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK9HRtD7fQB6",
        "outputId": "379bb45d-f20a-4ffb-ae1d-3ac758cedf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "real_path = '/content/drive/MyDrive/dataset/original dataset'  # Corrected \"original\"\n",
        "forge_path = '/content/drive/MyDrive/dataset/fraud dataset'\n",
        "\n",
        "# Check if directories exist\n",
        "if not os.path.exists(real_path):\n",
        "    print(f\"The directory {real_path} does not exist.\")\n",
        "if not os.path.exists(forge_path):\n",
        "    print(f\"The directory {forge_path} does not exist.\")\n",
        "\n",
        "# Load images if directories are valid\n",
        "real_images = []\n",
        "if os.path.exists(real_path):\n",
        "    for img_name in os.listdir(real_path):\n",
        "        img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "        real_images.append(img)\n",
        "real_images = np.array(real_images, dtype=object)\n",
        "\n",
        "forge_images = []\n",
        "if os.path.exists(forge_path):\n",
        "    for img_name in os.listdir(forge_path):\n",
        "        img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "        forge_images.append(img)\n",
        "forge_images = np.array(forge_images, dtype=object)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrMJyFOjd7pm",
        "outputId": "2214c3e7-fa25-49cb-fe00-5344628e0125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The directory /content/drive/MyDrive/dataset/original dataset does not exist.\n",
            "The directory /content/drive/MyDrive/dataset/fraud dataset does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spliting the Training and Testing Images"
      ],
      "metadata": {
        "id": "WWHtMFP1eDtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of real images:\", len(real_images))\n",
        "print(\"Number of forged images:\", len(forge_images))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODFzzALBhBrM",
        "outputId": "50f17c42-47f2-46cf-e318-aa88d4c1bcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of real images: 0\n",
            "Number of forged images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verify if images were loaded\n",
        "if len(real_images) == 0:\n",
        "    print(\"No images found in the real images directory.\")\n",
        "if len(forge_images) == 0:\n",
        "    print(\"No images found in the forged images directory.\")\n",
        "\n",
        "# Proceed if both lists are not empty\n",
        "if len(real_images) > 0 and len(forge_images) > 0:\n",
        "    real_labels = np.zeros(len(real_images))\n",
        "    forge_labels = np.ones(len(forge_images))\n",
        "\n",
        "    X = np.concatenate((real_images, forge_images), axis=0)\n",
        "    y = np.concatenate((real_labels, forge_labels), axis=0)\n",
        "\n",
        "    # Perform train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(\"Train-test split completed successfully.\")\n",
        "else:\n",
        "    print(\"Unable to perform train-test split due to missing images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aJeD0O-eGzm",
        "outputId": "b5591e16-df0c-4d29-ae17-97cedb15cb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No images found in the real images directory.\n",
            "No images found in the forged images directory.\n",
            "Unable to perform train-test split due to missing images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the Data and Normalizing it"
      ],
      "metadata": {
        "id": "9BHXn0DYeK75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Corrected paths\n",
        "real_path = '/content/drive/MyDrive/dataset/original dataset'\n",
        "forge_path = '/content/drive/MyDrive/dataset/fraud dataset'\n",
        "\n",
        "# Set the image size to 128x128\n",
        "img_size = (128, 128)\n",
        "\n",
        "real_images = []\n",
        "if os.path.exists(real_path):\n",
        "    for img_name in os.listdir(real_path):\n",
        "        img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:  # Check if the image was loaded successfully\n",
        "            img = cv2.resize(img, img_size)\n",
        "            real_images.append(img)\n",
        "    real_images = np.array(real_images)\n",
        "else:\n",
        "    print(f\"Directory {real_path} does not exist.\")\n",
        "\n",
        "forge_images = []\n",
        "if os.path.exists(forge_path):\n",
        "    for img_name in os.listdir(forge_path):\n",
        "        img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:  # Check if the image was loaded successfully\n",
        "            img = cv2.resize(img, img_size)\n",
        "            forge_images.append(img)\n",
        "    forge_images = np.array(forge_images)\n",
        "else:\n",
        "    print(f\"Directory {forge_path} does not exist.\")\n",
        "\n",
        "# Normalize the data if images are loaded\n",
        "if len(real_images) > 0:\n",
        "    real_images = real_images.astype('float32') / 255.0\n",
        "if len(forge_images) > 0:\n",
        "    forge_images = forge_images.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEQoHP8ZeMDx",
        "outputId": "88699e77-54b7-4ac5-d089-91fd25e738d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/drive/MyDrive/dataset/original dataset does not exist.\n",
            "Directory /content/drive/MyDrive/dataset/fraud dataset does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create labels for the real and forged signatures"
      ],
      "metadata": {
        "id": "2foLAVUDi9tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_real_images = len(real_images)\n",
        "num_forge_images = len(forge_images)\n",
        "\n",
        "# Create labels for the real and forged signatures\n",
        "real_labels = np.zeros(num_real_images, dtype=int)\n",
        "forge_labels = np.ones(num_forge_images, dtype=int)\n",
        "\n",
        "# Concatenate the real and forged images and labels\n",
        "X = np.concatenate((real_images, forge_images), axis=0)\n",
        "y = np.concatenate((real_labels, forge_labels), axis=0)"
      ],
      "metadata": {
        "id": "WtfD9nRTi-j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshaping the Training Set"
      ],
      "metadata": {
        "id": "kuWzxytUjCY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# create dummy data\n",
        "X_train = np.random.rand(40, 128, 128)\n",
        "\n",
        "# add another dimension to the array\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# reshape the array\n",
        "X_train = X_train.reshape(X_train.shape[0], 128, 128, 1)\n",
        "\n",
        "print(X_train.shape)  # output: (40, 128, 128, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_xwEUTEjDWo",
        "outputId": "79afc3d5-b972-4f24-e2ae-3d9de39a02c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshaping the Test Set"
      ],
      "metadata": {
        "id": "RJQyJIpWjGfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# create dummy data\n",
        "X_test = np.random.rand(40, 128, 128)\n",
        "\n",
        "# add another dimension to the array\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# reshape the array\n",
        "X_test = X_train.reshape(X_test.shape[0], 128, 128, 1)\n",
        "\n",
        "print(X_train.shape)  # output: (40, 128, 128, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbdYST4TjHoA",
        "outputId": "cb9bfa3e-051c-44c1-a543-47f0ed8797f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making the CNN model"
      ],
      "metadata": {
        "id": "5M_q9LTyjJ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(128, 128, 1)))\n",
        "\n",
        "# Add a max pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add another convolutional layer\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add another max pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 neurons and a relu activation function\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Add a dropout layer to reduce overfitting\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# Add the output layer with a sigmoid activation function\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "Nt_zPGB-jM-D",
        "outputId": "de039c4c-b244-4378-db63-d9aaf82a814c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m7,372,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,372,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,391,873\u001b[0m (28.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,391,873</span> (28.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,391,873\u001b[0m (28.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,391,873</span> (28.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating the Mode"
      ],
      "metadata": {
        "id": "YWYtfBfajVcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming real_images and forge_images were defined in previous code cells\n",
        "real_labels = np.zeros(real_images.shape[0]) if len(real_images) > 0 else []\n",
        "forge_labels = np.ones(forge_images.shape[0]) if len(forge_images) > 0 else []\n",
        "\n",
        "# Check if data exists before proceeding\n",
        "if len(real_labels) > 0 and len(forge_labels) > 0:\n",
        "    X = np.concatenate((real_images, forge_images), axis=0)\n",
        "    y = np.concatenate((real_labels, forge_labels), axis=0)\n",
        "\n",
        "    # Perform train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Compile and train the model if the split was successful\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "    print(\"Training completed successfully.\")\n",
        "else:\n",
        "    print(\"Data is missing. Please ensure real_images and forge_images contain images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBET-M0VjW-X",
        "outputId": "b4975d1c-0469-4879-c78c-77fbac109dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is missing. Please ensure real_images and forge_images contain images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Loss and Accuracy"
      ],
      "metadata": {
        "id": "1feT_OEtjuF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assume X is your dataset and y are the corresponding labels\n",
        "X = np.random.rand(1000, 128, 128, 1)  # Example image data\n",
        "y = np.random.randint(2, size=1000)    # Example binary labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "QNhvpylnju_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Example data preparation\n",
        "X = np.random.rand(1000, 128, 128, 1)  # Your input data\n",
        "y = np.random.randint(2, size=1000)    # Your labels\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azNCuPIakZW0",
        "outputId": "5a2764d5-7ea7-4934-920f-293798298595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5057 - loss: 0.7229 - val_accuracy: 0.4850 - val_loss: 0.6976\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5105 - loss: 0.6943 - val_accuracy: 0.4850 - val_loss: 0.6948\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 960ms/step - accuracy: 0.4886 - loss: 0.6940 - val_accuracy: 0.4850 - val_loss: 0.6960\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 983ms/step - accuracy: 0.5211 - loss: 0.6923 - val_accuracy: 0.4850 - val_loss: 0.6942\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 947ms/step - accuracy: 0.5351 - loss: 0.6928 - val_accuracy: 0.4850 - val_loss: 0.6936\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.5251 - loss: 0.6925 - val_accuracy: 0.4850 - val_loss: 0.6940\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 950ms/step - accuracy: 0.5486 - loss: 0.6915 - val_accuracy: 0.4850 - val_loss: 0.6946\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.5451 - loss: 0.6905 - val_accuracy: 0.4850 - val_loss: 0.6950\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5477 - loss: 0.6908 - val_accuracy: 0.4850 - val_loss: 0.6951\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 936ms/step - accuracy: 0.5380 - loss: 0.6915 - val_accuracy: 0.4850 - val_loss: 0.6953\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 980ms/step - accuracy: 0.5189 - loss: 0.6921 - val_accuracy: 0.4850 - val_loss: 0.6953\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 958ms/step - accuracy: 0.5382 - loss: 0.6910 - val_accuracy: 0.4850 - val_loss: 0.6957\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 924ms/step - accuracy: 0.5129 - loss: 0.6934 - val_accuracy: 0.4850 - val_loss: 0.6957\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.5441 - loss: 0.6904 - val_accuracy: 0.4850 - val_loss: 0.6959\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5125 - loss: 0.6938 - val_accuracy: 0.4850 - val_loss: 0.6959\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 939ms/step - accuracy: 0.5383 - loss: 0.6908 - val_accuracy: 0.4850 - val_loss: 0.6960\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 939ms/step - accuracy: 0.5391 - loss: 0.6903 - val_accuracy: 0.4850 - val_loss: 0.6961\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.5063 - loss: 0.6934 - val_accuracy: 0.4850 - val_loss: 0.6961\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 999ms/step - accuracy: 0.5331 - loss: 0.6906 - val_accuracy: 0.4850 - val_loss: 0.6964\n",
            "Epoch 20/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 981ms/step - accuracy: 0.5317 - loss: 0.6913 - val_accuracy: 0.4850 - val_loss: 0.6962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detection of Real and Forged Signature"
      ],
      "metadata": {
        "id": "9Uv9X-Ykkg_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load a signature image\n",
        "image_path = '/content/drive/MyDrive/dataset/orininal dataset/agh1_1.jpg'\n",
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if img is None:\n",
        "    print(f\"Error: Could not load image from path: {image_path}\")\n",
        "else:\n",
        "    # Resize the image\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "    img = np.array(img).reshape(1, 128, 128, 1) / 255.0\n",
        "\n",
        "    # Predict the class of the signature image\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    if prediction < 0.5:\n",
        "        print(\"The signature is real.\")\n",
        "    else:\n",
        "        print(\"The signature is forged.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgQY8UafkiXF",
        "outputId": "197e5bc5-137d-4d5a-aaee-f92de6edf22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not load image from path: /content/drive/MyDrive/dataset/orininal dataset/agh1_1.jpg\n"
          ]
        }
      ]
    }
  ]
}